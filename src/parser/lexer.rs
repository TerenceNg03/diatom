use std::str::Chars;

use super::error::{ErrorReporter, FileLocation, LineLocation};

/// A enumerate of all tokens possibly generated by [Lexer][crate::parser::lexer::Lexer].
pub enum Token {
    Unknown,
    NewLine,
    Str(String),
    Integer(i64),
    Float(f64),
    Id(String),
    Key(Keyword),
    Op(Operator),
}

/// A enum of all keywords
pub enum Keyword {
    TRUE,
    FALSE,
    DO,
    END,
    IF,
    THEN,
    ELSE,
    CASE,
    IN,
    FOR,
    NIL,
    ASSERT,
    RETURN,
    BREAK,
    CONTINUE,
}

/// A enum of all operators
pub enum Operator {
    Plus,
    Minus,
    Exp,
    Mul,
    DivFloor,
    Div,
    Mod,
    Range,
    And,
    Or,
    Not,
    GT,
    GE,
    EQ,
    NE,
    LT,
    LE,
    Assign,
    Comma,
}

struct FileIterator<'a> {
    file_content: &'a str,
    location: LineLocation,
    iterator: Chars<'a>,
}

impl<'a> FileIterator<'a> {
    fn new(file_content: &'a str) -> Self {
        Self {
            file_content,
            location: LineLocation::new(0, 0),
            iterator: file_content.chars(),
        }
    }

    /// Return next character. Useful to lookahead.
    fn peek(&self) -> Option<char> {
        let iter = self.iterator.clone();
        iter.next()
    }

    /// Return current location's clone.
    fn get_location(&self) -> LineLocation {
        self.location.clone()
    }
}

impl<'a> Iterator for FileIterator<'a>{
    type Item = char;
    fn next(&mut self) -> Option<Self::Item> {
        let next_item = self.iterator.next();
        match next_item {
            Some(c) => {
                if c == '\n' {
                    self.location.line += 1;
                    self.location.offset = 0;
                } else {
                    self.location.offset += 1;
                };
            }
            None => (),
        };
        next_item
    }
}

/// The lexical analyzer for Diatom
///
/// Note: This lexer assumes that newline character only contains '\n'. Any '\r' is ignored and
/// does not count as a newline.
pub struct Lexer<'a> {
    file_content: &'a str,
    error_reporter: ErrorReporter,
    tokens: Vec<(Token, FileLocation)>,
}

impl<'a> Lexer<'a> {
    pub fn new(file_content: &'a str) -> Self {
        let mut lexer = Self {
            file_content,
            error_reporter: ErrorReporter::new(),
            tokens: vec![],
        };
        lexer.parse();
        lexer
    }

    pub fn has_error(&self) -> bool {
        !self.error_reporter.is_empty()
    }

    /// Parse numeric types, aka int & float.
    fn parse_num(&mut self, iter: &mut FileIterator){
        todo!()
    }

    /// Parse keyword or Identifier
    fn parse_id_or_key(&mut self, iter: &mut FileIterator){
        todo!()
    }

    /// Parse string token
    fn parse_string(&mut self, iter: &mut FileIterator){
        todo!()
    }

    /// Parse all tokens
    fn parse(&mut self) {
        let mut iter = FileIterator::new(self.file_content);
        loop {
            let c = iter.peek();
            match c {
                Some(c) => {
                   match c {
                       '0'..='9' => self.parse_num(&mut iter),
                       '"' | '\'' => self.parse_string(&mut iter),
                       '\n' => {
                           let start = iter.get_location(); 
                           let _ = iter.next();
                           let end = iter.get_location();
                           self.tokens.push((Token::NewLine, FileLocation::new(start, end)));
                       },
                       ' ' | '\t' => (), // Ignore whitespace
                       _ => self.parse_id_or_key(&mut iter),
                   } 
                },
                None => {
                    break;
                }
            }
            
    }
    }
}
